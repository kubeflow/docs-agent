# PIPELINE DEFINITION
# Name: github-rag-feast
# Description: RAG pipeline: GitHub docs -> chunk -> embed -> Feast
# Inputs:
#    base_url: str [Default: 'https://www.kubeflow.org/docs']
#    chunk_overlap: int [Default: 100.0]
#    chunk_size: int [Default: 1000.0]
#    directory_path: str [Default: 'content/en']
#    feast_online_store_host: str [Default: 'http://milvus.santhosh.svc.cluster.local']
#    feast_project: str [Default: 'kubeflow_docs']
#    github_token: str [Default: '']
#    repo_name: str [Default: 'website']
#    repo_owner: str [Default: 'kubeflow']
components:
  comp-chunk-and-embed:
    executorLabel: exec-chunk-and-embed
    inputDefinitions:
      artifacts:
        github_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        base_url:
          parameterType: STRING
        chunk_overlap:
          parameterType: NUMBER_INTEGER
        chunk_size:
          parameterType: NUMBER_INTEGER
        repo_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        embedded_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-download-github-directory:
    executorLabel: exec-download-github-directory
    inputDefinitions:
      parameters:
        directory_path:
          parameterType: STRING
        github_token:
          parameterType: STRING
        repo_name:
          parameterType: STRING
        repo_owner:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        github_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-store-via-feast:
    executorLabel: exec-store-via-feast
    inputDefinitions:
      artifacts:
        embedded_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        feast_online_store_host:
          parameterType: STRING
        feast_project:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-chunk-and-embed:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - chunk_and_embed
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'sentence-transformers'\
          \ 'langchain-text-splitters'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef chunk_and_embed(\n    github_data: dsl.Input[dsl.Dataset],\n\
          \    repo_name: str,\n    base_url: str,\n    chunk_size: int,\n    chunk_overlap:\
          \ int,\n    embedded_data: dsl.Output[dsl.Dataset]\n):\n    import json\n\
          \    import os\n    import re\n    from sentence_transformers import SentenceTransformer\n\
          \    from langchain_text_splitters import RecursiveCharacterTextSplitter\n\
          \n    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n\
          \    print(\"Model loaded on CPU\")\n\n    records = []\n\n    with open(github_data.path,\
          \ 'r', encoding='utf-8') as f:\n        for line in f:\n            file_data\
          \ = json.loads(line)\n            content = file_data['content']\n\n   \
          \         # AGGRESSIVE CLEANING FOR BETTER EMBEDDINGS\n\n            # Remove\
          \ Hugo frontmatter (both --- and +++ styles)\n            content = re.sub(r'^\\\
          s*[+\\-]{3,}.*?[+\\-]{3,}\\s*', '', content, flags=re.DOTALL | re.MULTILINE)\n\
          \n            # Remove Hugo template syntax\n            content = re.sub(r'\\\
          {\\{.*?\\}\\}', '', content, flags=re.DOTALL)\n\n            # Remove HTML\
          \ comments and tags\n            content = re.sub(r'<!--.*?-->', '', content,\
          \ flags=re.DOTALL)\n            content = re.sub(r'<[^>]+>', ' ', content)\n\
          \n            # Remove navigation/menu artifacts\n            content =\
          \ re.sub(r'\\b(Get Started|Contribute|GenAI|Home|Menu|Navigation)\\b', '',\
          \ content, flags=re.IGNORECASE)\n\n            # Clean up URLs and links\n\
          \            content = re.sub(r'https?://[^\\s]+', '', content)\n      \
          \      content = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', content)\
          \  # Convert [text](url) to text\n\n            # Remove excessive whitespace\
          \ and normalize\n            content = re.sub(r'\\s+', ' ', content)  #\
          \ Multiple spaces to single\n            content = re.sub(r'\\n\\s*\\n\\\
          s*\\n+', '\\n\\n', content)  # Multiple newlines to double\n           \
          \ content = content.strip()\n\n            # Skip files that are too short\
          \ after cleaning\n            if len(content) < 50:\n                print(f\"\
          Skipping file after cleaning: {file_data['path']} ({len(content)} chars)\"\
          )\n                continue\n\n            # Build citation URL (same as\
          \ before)\n            path_parts = file_data['path'].split('/')\n     \
          \       if 'content/en/docs' in file_data['path']:\n                docs_index\
          \ = path_parts.index('docs')\n                url_path = '/'.join(path_parts[docs_index+1:])\n\
          \                url_path = os.path.splitext(url_path)[0]\n            \
          \    citation_url = f\"{base_url}/{url_path}\"\n            else:\n    \
          \            citation_url = f\"{base_url}/{file_data['path']}\"\n\n    \
          \        file_unique_id = f\"{repo_name}:{file_data['path']}\"\n\n     \
          \       # Create splitter\n            text_splitter = RecursiveCharacterTextSplitter(\n\
          \                chunk_size=chunk_size,\n                chunk_overlap=chunk_overlap,\n\
          \                length_function=len,\n                separators=[\"\\\
          n\\n\", \"\\n\", \". \", \" \", \"\"]\n            )\n\n            # Split\
          \ into chunks\n            chunks = text_splitter.split_text(content)\n\n\
          \            print(f\"File: {file_data['path']} -> {len(chunks)} chunks\
          \ (avg: {sum(len(c) for c in chunks)/len(chunks):.0f} chars)\")\n\n    \
          \        # Create embeddings\n            for chunk_idx, chunk in enumerate(chunks):\n\
          \                embedding = model.encode(chunk).tolist()\n            \
          \    records.append({\n                    'file_unique_id': f\"{file_unique_id}:{chunk_idx}\"\
          ,\n                    'repo_name': repo_name,\n                    'file_path':\
          \ file_data['path'],\n                    'file_name': file_data['file_name'],\n\
          \                    'citation_url': citation_url,\n                   \
          \ 'chunk_index': chunk_idx,\n                    'content_text': chunk,\n\
          \                    'embedding': embedding\n                })\n\n    print(f\"\
          Created {len(records)} total chunks\")\n\n    with open(embedded_data.path,\
          \ 'w', encoding='utf-8') as f:\n        for record in records:\n       \
          \     f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n\n"
        image: python:3.13-slim
    exec-download-github-directory:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - download_github_directory
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'requests' 'beautifulsoup4'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.15.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef download_github_directory(\n    repo_owner: str,\n    repo_name:\
          \ str,\n    directory_path: str,\n    github_token: str,\n    github_data:\
          \ dsl.Output[dsl.Dataset]\n):\n    import requests\n    import json\n  \
          \  import base64\n    from bs4 import BeautifulSoup\n\n    headers = {\"\
          Authorization\": f\"token {github_token}\"} if github_token else {}\n  \
          \  api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{directory_path}\"\
          \n\n    def get_files_recursive(url):\n        files = []\n        try:\n\
          \            response = requests.get(url, headers=headers)\n           \
          \ response.raise_for_status()\n            items = response.json()\n\n \
          \           for item in items:\n                if item['type'] == 'file'\
          \ and (item['name'].endswith('.md') or item['name'].endswith('.html')):\n\
          \                    file_response = requests.get(item['url'], headers=headers)\n\
          \                    file_response.raise_for_status()\n                \
          \    file_data = file_response.json()\n                    content = base64.b64decode(file_data['content']).decode('utf-8')\n\
          \n                    # Extract text from HTML files\n                 \
          \   if item['name'].endswith('.html'):\n                        soup = BeautifulSoup(content,\
          \ 'html.parser')\n                        content = soup.get_text(separator='\
          \ ', strip=True)\n\n                    files.append({\n               \
          \         'path': item['path'],\n                        'content': content,\n\
          \                        'file_name': item['name']\n                   \
          \ })\n                elif item['type'] == 'dir':\n                    files.extend(get_files_recursive(item['url']))\n\
          \        except Exception as e:\n            print(f\"Error fetching {url}:\
          \ {e}\")\n        return files\n\n    files = get_files_recursive(api_url)\n\
          \    print(f\"Downloaded {len(files)} files\")\n\n    with open(github_data.path,\
          \ 'w', encoding='utf-8') as f:\n        for file_data in files:\n      \
          \      f.write(json.dumps(file_data, ensure_ascii=False) + '\\n')\n\n"
        image: python:3.13-slim
    exec-store-via-feast:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - store_via_feast
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'feast[milvus]'\
          \ 'pandas' 'marshmallow>=3.13.0'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.15.2' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef store_via_feast(\n    embedded_data: dsl.Input[dsl.Dataset],\n\
          \    feast_online_store_host: str,\n    feast_project: str,\n):\n    import\
          \ json\n    import os\n    import pandas as pd\n    import inspect\n   \
          \ from datetime import datetime, timedelta\n    from feast import FeatureStore,\
          \ Entity, FeatureView, Field, FileSource\n    from feast.types import String,\
          \ Int64, Float32, Array, UnixTimestamp\n\n    # Patch Feast VARCHAR limit\
          \ (hardcoded 512 -> 4096) and reload module\n    import importlib\n    import\
          \ feast.infra.online_stores.milvus_online_store.milvus as milvus_mod\n \
          \   src_file = inspect.getfile(milvus_mod)\n    with open(src_file, \"r\"\
          ) as f:\n        content = f.read()\n    if \"max_length=512\" in content:\n\
          \        with open(src_file, \"w\") as f:\n            f.write(content.replace(\"\
          max_length=512\", \"max_length=4096\"))\n        print(\"Patched Feast VARCHAR\
          \ limit to 4096\")\n    importlib.reload(milvus_mod)\n    print(\"Reloaded\
          \ Feast Milvus module\")\n\n    # Drop existing collection so it gets recreated\
          \ with the patched schema\n    from pymilvus import connections, utility\n\
          \    milvus_host = feast_online_store_host.replace(\"http://\", \"\").replace(\"\
          https://\", \"\")\n    connections.connect(\"default\", host=milvus_host,\
          \ port=\"19530\")\n    collection_name = f\"{feast_project}_docs_rag\"\n\
          \    if utility.has_collection(collection_name):\n        utility.drop_collection(collection_name)\n\
          \        print(f\"Dropped existing collection: {collection_name}\")\n  \
          \  connections.disconnect(\"default\")\n\n    feast_dir = \"/tmp/feast_repo\"\
          \n    os.makedirs(f\"{feast_dir}/data\", exist_ok=True)\n\n    with open(f\"\
          {feast_dir}/feature_store.yaml\", \"w\") as f:\n        f.write(f\"\"\"\
          project: {feast_project}\nprovider: local\nregistry: data/registry.db\n\
          online_store:\n  type: milvus\n  host: {feast_online_store_host}\n  port:\
          \ 19530\n  username: root\n  password: Milvus\n  vector_enabled: true\n\
          \  embedding_dim: 768\n  index_type: IVF_FLAT\n  metric_type: COSINE\noffline_store:\n\
          \  type: file\nentity_key_serialization_version: 3\nauth:\n  type: no_auth\n\
          \"\"\")\n\n    # Define Feast objects inline\n    doc_chunk = Entity(name=\"\
          doc_chunk\", join_keys=[\"file_unique_id\"])\n    docs_source = FileSource(path=\"\
          data/embedded_docs.parquet\", timestamp_field=\"event_timestamp\")\n   \
          \ docs_rag = FeatureView(\n        name=\"docs_rag\",\n        entities=[doc_chunk],\n\
          \        schema=[\n            Field(name=\"file_unique_id\", dtype=String),\n\
          \            Field(name=\"repo_name\", dtype=String),\n            Field(name=\"\
          file_path\", dtype=String),\n            Field(name=\"file_name\", dtype=String),\n\
          \            Field(name=\"citation_url\", dtype=String),\n            Field(name=\"\
          chunk_index\", dtype=Int64),\n            Field(name=\"content_text\", dtype=String),\n\
          \            Field(name=\"vector\", dtype=Array(Float32), vector_index=True,\
          \ vector_search_metric=\"COSINE\"),\n            Field(name=\"event_timestamp\"\
          , dtype=UnixTimestamp),\n        ],\n        source=docs_source,\n     \
          \   ttl=timedelta(days=30),\n    )\n\n    records = []\n    with open(embedded_data.path,\
          \ 'r', encoding='utf-8') as f:\n        for line in f:\n            record\
          \ = json.loads(line)\n            records.append({\n                \"file_unique_id\"\
          : record['file_unique_id'],\n                \"repo_name\": record[\"repo_name\"\
          ],\n                \"file_path\": record[\"file_path\"],\n            \
          \    \"file_name\": record[\"file_name\"],\n                \"citation_url\"\
          : record[\"citation_url\"],\n                \"chunk_index\": record[\"\
          chunk_index\"],\n                \"content_text\": record[\"content_text\"\
          ],\n                \"vector\": record[\"embedding\"],\n               \
          \ \"event_timestamp\": datetime.now(),\n            })\n\n    df = pd.DataFrame(records)\n\
          \n    store = FeatureStore(repo_path=feast_dir)\n    store.apply([doc_chunk,\
          \ docs_source, docs_rag])\n    store.write_to_online_store(feature_view_name=\"\
          docs_rag\", df=df)\n    print(f\"Wrote {len(records)} records to Feast online\
          \ store\")\n\n"
        image: python:3.13-slim
pipelineInfo:
  description: 'RAG pipeline: GitHub docs -> chunk -> embed -> Feast'
  name: github-rag-feast
root:
  dag:
    tasks:
      chunk-and-embed:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-chunk-and-embed
        dependentTasks:
        - download-github-directory
        inputs:
          artifacts:
            github_data:
              taskOutputArtifact:
                outputArtifactKey: github_data
                producerTask: download-github-directory
          parameters:
            base_url:
              componentInputParameter: base_url
            chunk_overlap:
              componentInputParameter: chunk_overlap
            chunk_size:
              componentInputParameter: chunk_size
            repo_name:
              componentInputParameter: repo_name
        taskInfo:
          name: chunk-and-embed
      download-github-directory:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-download-github-directory
        inputs:
          parameters:
            directory_path:
              componentInputParameter: directory_path
            github_token:
              componentInputParameter: github_token
            repo_name:
              componentInputParameter: repo_name
            repo_owner:
              componentInputParameter: repo_owner
        taskInfo:
          name: download-github-directory
      store-via-feast:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-store-via-feast
        dependentTasks:
        - chunk-and-embed
        inputs:
          artifacts:
            embedded_data:
              taskOutputArtifact:
                outputArtifactKey: embedded_data
                producerTask: chunk-and-embed
          parameters:
            feast_online_store_host:
              componentInputParameter: feast_online_store_host
            feast_project:
              componentInputParameter: feast_project
        taskInfo:
          name: store-via-feast
  inputDefinitions:
    parameters:
      base_url:
        defaultValue: https://www.kubeflow.org/docs
        isOptional: true
        parameterType: STRING
      chunk_overlap:
        defaultValue: 100.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      chunk_size:
        defaultValue: 1000.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      directory_path:
        defaultValue: content/en
        isOptional: true
        parameterType: STRING
      feast_online_store_host:
        defaultValue: http://milvus.santhosh.svc.cluster.local
        isOptional: true
        parameterType: STRING
      feast_project:
        defaultValue: kubeflow_docs
        isOptional: true
        parameterType: STRING
      github_token:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      repo_name:
        defaultValue: website
        isOptional: true
        parameterType: STRING
      repo_owner:
        defaultValue: kubeflow
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.15.2
